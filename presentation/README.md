# Vanishing and Exploding Gradients

Slides presented as part of the assignment for the course *Machine Learning*. The slides cover the problems of vanishing and exploding gradients in deep networks, as well as solutions to these problems.

## Content

The slides cover the following topics:

- **Vanishing Gradients:**
  - The problem of vanishing gradients in deep networks.
  - Weight initialization techniques.
  - Batch normalization as a solution.

- **Exploding Gradients:**
  - The problem of exploding gradients during backpropagation.
  - Gradient clipping techniques.
  - Comparison between value clipping and norm clipping.

## Presentation

You can access the slides by clicking [here](github.com/thaisaraujom/machine-learning/tree/main/presentation/vanishing_and_exploding_gradients.pdf).

## Authors

- [Lucas Torres](https://github.com/Lucastmarques)
- [Miguel Amaral](https://github.com/MiguelEuripedes)
- [Morsinaldo Medeiros](https://github.com/Morsinaldo)
- [Tha√≠s Medeiros](https://github.com/thaisaraujom)
